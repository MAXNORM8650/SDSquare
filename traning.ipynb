{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723e92eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "initialization of _internal failed without raising an exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mGaussianDiffusion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianDiffusionModel, get_beta_schedule\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUNet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNetModel, update_ema_params\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimplex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Simplex_CLASS\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_beta_schedule\u001b[39m(num_diffusion_steps, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     13\u001b[0m     betas \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\simplex.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m animation\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m njit, prange\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimplex_CLASS\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\en_2\\lib\\site-packages\\numba\\__init__.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (cfunc, generated_jit, jit, njit, stencil,\n\u001b[0;32m     39\u001b[0m                                    jit_module)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Re-export vectorize decorators and the thread layer querying function\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (vectorize, guvectorize, threading_layer,\n\u001b[0;32m     43\u001b[0m                             get_num_threads, set_num_threads)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Re-export Numpy helpers\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_support\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m carray, farray, from_dtype\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\en_2\\lib\\site-packages\\numba\\np\\ufunc\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vectorize, GUVectorize, vectorize, guvectorize\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyUFunc_None, PyUFunc_Zero, PyUFunc_One\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _internal, array_exprs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\en_2\\lib\\site-packages\\numba\\np\\ufunc\\decorators.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _internal\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mufunc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelUFuncBuilder, ParallelGUFuncBuilder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DelayedRegistry\n",
      "\u001b[1;31mSystemError\u001b[0m: initialization of _internal failed without raising an exception"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "from random import seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from torch import optim\n",
    "\n",
    "import dataset\n",
    "import evaluation\n",
    "from GaussianDiffusion import GaussianDiffusionModel, get_beta_schedule\n",
    "from helpers import *\n",
    "from UNet import UNetModel, update_ema_params\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ROOT_DIR = \"./\"\n",
    "\n",
    "\n",
    "def train(training_dataset_loader, testing_dataset_loader, args, resume):\n",
    "    \"\"\"\n",
    "\n",
    "    :param training_dataset_loader: cycle(dataloader) instance for training\n",
    "    :param testing_dataset_loader:  cycle(dataloader) instance for testing\n",
    "    :param args: dictionary of parameters\n",
    "    :param resume: dictionary of parameters if continuing training from checkpoint\n",
    "    :return: Trained model and tested\n",
    "    \"\"\"\n",
    "\n",
    "    in_channels = 1\n",
    "    if args[\"dataset\"].lower() == \"cifar\" or args[\"dataset\"].lower() == \"leather\":\n",
    "        in_channels = 3\n",
    "\n",
    "    if args[\"channels\"] != \"\":\n",
    "        in_channels = args[\"channels\"]\n",
    "\n",
    "    model = UNetModel(\n",
    "            args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], dropout=args[\n",
    "                \"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "            in_channels=in_channels\n",
    "            )\n",
    "\n",
    "    betas = get_beta_schedule(args['T'], args['beta_schedule'])\n",
    "\n",
    "    diffusion = GaussianDiffusionModel(\n",
    "            args['img_size'], betas, loss_weight=args['loss_weight'],\n",
    "            loss_type=args['loss-type'], noise=args[\"noise_fn\"], img_channels=in_channels\n",
    "            )\n",
    "\n",
    "    if resume:\n",
    "\n",
    "        if \"unet\" in resume:\n",
    "            model.load_state_dict(resume[\"unet\"])\n",
    "        else:\n",
    "            model.load_state_dict(resume[\"ema\"])\n",
    "\n",
    "        ema = UNetModel(\n",
    "                args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'],\n",
    "                dropout=args[\"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "                in_channels=in_channels\n",
    "                )\n",
    "        ema.load_state_dict(resume[\"ema\"])\n",
    "        start_epoch = resume['n_epoch']\n",
    "\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        ema = copy.deepcopy(model)\n",
    "\n",
    "    tqdm_epoch = range(start_epoch, args['EPOCHS'] + 1)\n",
    "    model.to(device)\n",
    "    ema.to(device)\n",
    "    optimiser = optim.AdamW(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'], betas=(0.9, 0.999))\n",
    "    if resume:\n",
    "        optimiser.load_state_dict(resume[\"optimizer_state_dict\"])\n",
    "\n",
    "    del resume\n",
    "    start_time = time.time()\n",
    "    losses = []\n",
    "    vlb = collections.deque([], maxlen=10)\n",
    "    iters = range(100 // args['Batch_Size']) if args[\"dataset\"].lower() != \"cifar\" else range(200)\n",
    "    # iters = range(100 // args['Batch_Size']) if args[\"dataset\"].lower() != \"cifar\" else range(150)\n",
    "\n",
    "    # dataset loop\n",
    "    for epoch in tqdm_epoch:\n",
    "        mean_loss = []\n",
    "\n",
    "        for i in iters:\n",
    "            data = next(training_dataset_loader)\n",
    "            if args[\"dataset\"] == \"cifar\":\n",
    "                # cifar outputs [data,class]\n",
    "                x = data[0].to(device)\n",
    "            else:\n",
    "                x = data[\"image\"]\n",
    "                x = x.to(device)\n",
    "\n",
    "            loss, estimates = diffusion.p_loss(model, x, args)\n",
    "\n",
    "            noisy, est = estimates[1], estimates[2]\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimiser.step()\n",
    "\n",
    "            update_ema_params(ema, model)\n",
    "            mean_loss.append(loss.data.cpu())\n",
    "\n",
    "            if epoch % 50 == 0 and i == 0:\n",
    "                row_size = min(8, args['Batch_Size'])\n",
    "                training_outputs(\n",
    "                        diffusion, x, est, noisy, epoch, row_size, save_imgs=args['save_imgs'],\n",
    "                        save_vids=args['save_vids'], ema=ema, args=args\n",
    "                        )\n",
    "\n",
    "        losses.append(np.mean(mean_loss))\n",
    "        if epoch % 200 == 0:\n",
    "            time_taken = time.time() - start_time\n",
    "            remaining_epochs = args['EPOCHS'] - epoch\n",
    "            time_per_epoch = time_taken / (epoch + 1 - start_epoch)\n",
    "            hours = remaining_epochs * time_per_epoch / 3600\n",
    "            mins = (hours % 1) * 60\n",
    "            hours = int(hours)\n",
    "\n",
    "            vlb_terms = diffusion.calc_total_vlb(x, model, args)\n",
    "            vlb.append(vlb_terms[\"total_vlb\"].mean(dim=-1).cpu().item())\n",
    "            print(\n",
    "                    f\"epoch: {epoch}, most recent total VLB: {vlb[-1]} mean total VLB:\"\n",
    "                    f\" {np.mean(vlb):.4f}, \"\n",
    "                    f\"prior vlb: {vlb_terms['prior_vlb'].mean(dim=-1).cpu().item():.2f}, vb: \"\n",
    "                    f\"{torch.mean(vlb_terms['vb'], dim=list(range(2))).cpu().item():.2f}, x_0_mse: \"\n",
    "                    f\"{torch.mean(vlb_terms['x_0_mse'], dim=list(range(2))).cpu().item():.2f}, mse: \"\n",
    "                    f\"{torch.mean(vlb_terms['mse'], dim=list(range(2))).cpu().item():.2f}\"\n",
    "                    f\" time elapsed {int(time_taken / 3600)}:{((time_taken / 3600) % 1) * 60:02.0f}, \"\n",
    "                    f\"est time remaining: {hours}:{mins:02.0f}\\r\"\n",
    "                    )\n",
    "            # else:\n",
    "            #\n",
    "            #     print(\n",
    "            #             f\"epoch: {epoch}, imgs trained: {(i + 1) * args['Batch_Size'] + epoch * 100}, last 20 epoch mean loss:\"\n",
    "            #             f\" {np.mean(losses[-20:]):.4f} , last 100 epoch mean loss:\"\n",
    "            #             f\" {np.mean(losses[-100:]) if len(losses) > 0 else 0:.4f}, \"\n",
    "            #             f\"time per epoch {time_per_epoch:.2f}s, time elapsed {int(time_taken / 3600)}:\"\n",
    "            #             f\"{((time_taken / 3600) % 1) * 60:02.0f}, est time remaining: {hours}:{mins:02.0f}\\r\"\n",
    "            #             )\n",
    "\n",
    "        if epoch % 1000 == 0 and epoch >= 0:\n",
    "            save(unet=model, args=args, optimiser=optimiser, final=False, ema=ema, epoch=epoch)\n",
    "\n",
    "    save(unet=model, args=args, optimiser=optimiser, final=True, ema=ema)\n",
    "\n",
    "    evaluation.testing(testing_dataset_loader, diffusion, ema=ema, args=args, model=model)\n",
    "\n",
    "\n",
    "def save(final, unet, optimiser, args, ema, loss=0, epoch=0):\n",
    "    \"\"\"\n",
    "    Save model final or checkpoint\n",
    "    :param final: bool for final vs checkpoint\n",
    "    :param unet: unet instance\n",
    "    :param optimiser: ADAM optim\n",
    "    :param args: model parameters\n",
    "    :param ema: ema instance\n",
    "    :param loss: loss for checkpoint\n",
    "    :param epoch: epoch for checkpoint\n",
    "    :return: saved model\n",
    "    \"\"\"\n",
    "    if final:\n",
    "        torch.save(\n",
    "                {\n",
    "                    'n_epoch':              args[\"EPOCHS\"],\n",
    "                    'model_state_dict':     unet.state_dict(),\n",
    "                    'optimizer_state_dict': optimiser.state_dict(),\n",
    "                    \"ema\":                  ema.state_dict(),\n",
    "                    \"args\":                 args\n",
    "                    # 'loss': LOSS,\n",
    "                    }, f'{ROOT_DIR}model/diff-params-ARGS={args[\"arg_num\"]}/params-final.pt'\n",
    "                )\n",
    "    else:\n",
    "        torch.save(\n",
    "                {\n",
    "                    'n_epoch':              epoch,\n",
    "                    'model_state_dict':     unet.state_dict(),\n",
    "                    'optimizer_state_dict': optimiser.state_dict(),\n",
    "                    \"args\":                 args,\n",
    "                    \"ema\":                  ema.state_dict(),\n",
    "                    'loss':                 loss,\n",
    "                    }, f'{ROOT_DIR}model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint/diff_epoch={epoch}.pt'\n",
    "                )\n",
    "\n",
    "\n",
    "def training_outputs(diffusion, x, est, noisy, epoch, row_size, ema, args, save_imgs=False, save_vids=False):\n",
    "    \"\"\"\n",
    "    Saves video & images based on args info\n",
    "    :param diffusion: diffusion model instance\n",
    "    :param x: x_0 real data value\n",
    "    :param est: estimate of the noise at x_t (output of the model)\n",
    "    :param noisy: x_t\n",
    "    :param epoch:\n",
    "    :param row_size: rows for outputs into torchvision.utils.make_grid\n",
    "    :param ema: exponential moving average unet for sampling\n",
    "    :param save_imgs: bool for saving imgs\n",
    "    :param save_vids: bool for saving diffusion videos\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(f'./diffusion-videos/ARGS={args[\"arg_num\"]}')\n",
    "        os.makedirs(f'./diffusion-training-images/ARGS={args[\"arg_num\"]}')\n",
    "    except OSError:\n",
    "        pass\n",
    "    if save_imgs:\n",
    "        if epoch % 100 == 0:\n",
    "            # for a given t, output x_0, & prediction of x_(t-1), and x_0\n",
    "            noise = torch.rand_like(x)\n",
    "            t = torch.randint(0, diffusion.num_timesteps, (x.shape[0],), device=x.device)\n",
    "            x_t = diffusion.sample_q(x, t, noise)\n",
    "            temp = diffusion.sample_p(ema, x_t, t)\n",
    "            out = torch.cat(\n",
    "                    (x[:row_size, ...].cpu(), temp[\"sample\"][:row_size, ...].cpu(),\n",
    "                     temp[\"pred_x_0\"][:row_size, ...].cpu())\n",
    "                    )\n",
    "            plt.title(f'real,sample,prediction x_0-{epoch}epoch')\n",
    "        else:\n",
    "            # for a given t, output x_0, x_t, & prediction of noise in x_t & MSE\n",
    "            out = torch.cat(\n",
    "                    (x[:row_size, ...].cpu(), noisy[:row_size, ...].cpu(), est[:row_size, ...].cpu(),\n",
    "                     (est - noisy).square().cpu()[:row_size, ...])\n",
    "                    )\n",
    "            plt.title(f'real,noisy,noise prediction,mse-{epoch}epoch')\n",
    "        plt.rcParams['figure.dpi'] = 150\n",
    "        plt.grid(False)\n",
    "        plt.imshow(gridify_output(out, row_size), cmap='gray')\n",
    "\n",
    "        plt.savefig(f'./diffusion-training-images/ARGS={args[\"arg_num\"]}/EPOCH={epoch}.png')\n",
    "        plt.clf()\n",
    "    if save_vids:\n",
    "        fig, ax = plt.subplots()\n",
    "        if epoch % 500 == 0:\n",
    "            plt.rcParams['figure.dpi'] = 200\n",
    "            if epoch % 1000 == 0:\n",
    "                out = diffusion.forward_backward(ema, x, \"half\", args['sample_distance'] // 2, denoise_fn=\"noise_fn\")\n",
    "            else:\n",
    "                out = diffusion.forward_backward(ema, x, \"half\", args['sample_distance'] // 4, denoise_fn=\"noise_fn\")\n",
    "            imgs = [[ax.imshow(gridify_output(x, row_size), animated=True)] for x in out]\n",
    "            ani = animation.ArtistAnimation(\n",
    "                    fig, imgs, interval=50, blit=True,\n",
    "                    repeat_delay=1000\n",
    "                    )\n",
    "\n",
    "            ani.save(f'{ROOT_DIR}diffusion-videos/ARGS={args[\"arg_num\"]}/sample-EPOCH={epoch}.mp4')\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d22006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "        Load arguments, run training and testing functions, then remove checkpoint directory\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # make directories\n",
    "    for i in ['./model/', \"./diffusion-videos/\", './diffusion-training-images/']:\n",
    "        try:\n",
    "            os.makedirs(i)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    # read file from argument\n",
    "    if len(sys.argv[1:]) > 0:\n",
    "        files = sys.argv[1:]\n",
    "    else:\n",
    "        raise ValueError(\"Missing file argument\")\n",
    "\n",
    "    # resume from final or resume from most recent checkpoint -> ran from specific slurm script?\n",
    "    resume = 0\n",
    "    if files[0] == \"RESUME_RECENT\":\n",
    "        resume = 1\n",
    "        files = files[1:]\n",
    "        if len(files) == 0:\n",
    "            raise ValueError(\"Missing file argument\")\n",
    "    elif files[0] == \"RESUME_FINAL\":\n",
    "        resume = 2\n",
    "        files = files[1:]\n",
    "        if len(files) == 0:\n",
    "            raise ValueError(\"Missing file argument\")\n",
    "\n",
    "    # allow different arg inputs ie 25 or args15 which are converted into argsNUM.json\n",
    "    file = files[0]\n",
    "    if file.isnumeric():\n",
    "        file = f\"args{file}.json\"\n",
    "    elif file[:4] == \"args\" and file[-5:] == \".json\":\n",
    "        pass\n",
    "    elif file[:4] == \"args\":\n",
    "        file = f\"args{file[4:]}.json\"\n",
    "    else:\n",
    "        raise ValueError(\"File Argument is not a json file\")\n",
    "\n",
    "    # load the json args\n",
    "    with open(f'{ROOT_DIR}test_args/{file}', 'r') as f:\n",
    "        args = json.load(f)\n",
    "    args['arg_num'] = file[4:-5]\n",
    "    args = defaultdict_from_json(args)\n",
    "\n",
    "    # make arg specific directories\n",
    "    for i in [f'./model/diff-params-ARGS={args[\"arg_num\"]}',\n",
    "              f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint',\n",
    "              f'./diffusion-videos/ARGS={args[\"arg_num\"]}',\n",
    "              f'./diffusion-training-images/ARGS={args[\"arg_num\"]}']:\n",
    "        try:\n",
    "            os.makedirs(i)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    print(file, args)\n",
    "    if args[\"channels\"] != \"\":\n",
    "        in_channels = args[\"channels\"]\n",
    "\n",
    "    # if dataset is cifar, load different training & test set\n",
    "    if args[\"dataset\"].lower() == \"cifar\":\n",
    "        training_dataset_loader_, testing_dataset_loader_ = dataset.load_CIFAR10(args, True), \\\n",
    "                                                            dataset.load_CIFAR10(args, False)\n",
    "        training_dataset_loader = dataset.cycle(training_dataset_loader_)\n",
    "        testing_dataset_loader = dataset.cycle(testing_dataset_loader_)\n",
    "    elif args[\"dataset\"].lower() == \"carpet\":\n",
    "        training_dataset = dataset.DAGM(\n",
    "                \"./DATASETS/CARPET/Class1\", False, args[\"img_size\"],\n",
    "                False\n",
    "                )\n",
    "        training_dataset_loader = dataset.init_dataset_loader(training_dataset, args)\n",
    "        testing_dataset = dataset.DAGM(\n",
    "                \"./DATASETS/CARPET/Class1\", True, args[\"img_size\"],\n",
    "                False\n",
    "                )\n",
    "        testing_dataset_loader = dataset.init_dataset_loader(testing_dataset, args)\n",
    "    elif args[\"dataset\"].lower() == \"leather\":\n",
    "        if in_channels == 3:\n",
    "            training_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=False, img_size=args[\"img_size\"],\n",
    "                    rgb=True\n",
    "                    )\n",
    "            testing_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=True, img_size=args[\"img_size\"],\n",
    "                    rgb=True, include_good=True\n",
    "                    )\n",
    "        else:\n",
    "            training_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=False, img_size=args[\"img_size\"],\n",
    "                    rgb=False\n",
    "                    )\n",
    "            testing_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=True, img_size=args[\"img_size\"],\n",
    "                    rgb=False, include_good=True\n",
    "                    )\n",
    "        training_dataset_loader = dataset.init_dataset_loader(training_dataset, args)\n",
    "        testing_dataset_loader = dataset.init_dataset_loader(testing_dataset, args)\n",
    "    else:\n",
    "        # load NFBS dataset\n",
    "        training_dataset, testing_dataset = dataset.init_datasets(ROOT_DIR, args)\n",
    "        training_dataset_loader = dataset.init_dataset_loader(training_dataset, args)\n",
    "        testing_dataset_loader = dataset.init_dataset_loader(testing_dataset, args)\n",
    "\n",
    "    # if resuming, loaded model is attached to the dictionary\n",
    "    loaded_model = {}\n",
    "    if resume:\n",
    "        if resume == 1:\n",
    "            checkpoints = os.listdir(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint')\n",
    "            checkpoints.sort(reverse=True)\n",
    "            for i in checkpoints:\n",
    "                try:\n",
    "                    file_dir = f\"./model/diff-params-ARGS={args['arg_num']}/checkpoint/{i}\"\n",
    "                    loaded_model = torch.load(file_dir, map_location=device)\n",
    "                    break\n",
    "                except RuntimeError:\n",
    "                    continue\n",
    "\n",
    "        else:\n",
    "            file_dir = f'./model/diff-params-ARGS={args[\"arg_num\"]}/params-final.pt'\n",
    "            loaded_model = torch.load(file_dir, map_location=device)\n",
    "\n",
    "    # load, pass args\n",
    "    train(training_dataset_loader, testing_dataset_loader, args, loaded_model)\n",
    "\n",
    "    # remove checkpoints after final_param is saved (due to storage requirements)\n",
    "    for file_remove in os.listdir(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint'):\n",
    "        os.remove(os.path.join(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint', file_remove))\n",
    "    os.removedirs(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    seed(1)\n",
    "\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
