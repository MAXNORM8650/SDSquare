{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09935cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTrain a noised image classifier on ImageNet.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train a noised image classifier on ImageNet.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f7974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "from guided_diffusion.bratsloader import BRATSDataset\n",
    "import blobfile as bf\n",
    "import torch as th\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "os.environ[\"PL_TORCH_DISTRIBUTED_BACKEND\"] = \"gloo\"\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "from torch.optim import AdamW\n",
    "from visdom import Visdom\n",
    "import numpy as np\n",
    "viz = Visdom(port=8097)\n",
    "loss_window = viz.line( Y=th.zeros((1)).cpu(), X=th.zeros((1)).cpu(), opts=dict(xlabel='epoch', ylabel='Loss', title='classification loss'))\n",
    "val_window = viz.line( Y=th.zeros((1)).cpu(), X=th.zeros((1)).cpu(), opts=dict(xlabel='epoch', ylabel='Loss', title='validation loss'))\n",
    "acc_window= viz.line( Y=th.zeros((1)).cpu(), X=th.zeros((1)).cpu(), opts=dict(xlabel='epoch', ylabel='acc', title='accuracy'))\n",
    "\n",
    "from guided_diffusion import dist_util, logger\n",
    "from guided_diffusion.fp16_util import MixedPrecisionTrainer\n",
    "from guided_diffusion.image_datasets import load_data\n",
    "from guided_diffusion.train_util import visualize\n",
    "from guided_diffusion.resample import create_named_schedule_sampler\n",
    "from guided_diffusion.script_util import (\n",
    "    add_dict_to_argparser,\n",
    "    args_to_dict,\n",
    "    classifier_and_diffusion_defaults,\n",
    "    create_classifier_and_diffusion,\n",
    ")\n",
    "from guided_diffusion.train_util import parse_resume_step_from_filename, log_loss_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f284fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "  \"image_size\": 256,\n",
    "  \"Batch_Size\": 8,\n",
    "  \"batch_size\": 8,\n",
    "  \"channels\": 3,\n",
    "  \"EPOCHS\": 4000,\n",
    "  \"iterations\":40000,\n",
    "  \"diffusion_steps\": 1000,\n",
    "  \"num_channels\": 192,\\\n",
    "  \"learn_sigma\":True,\n",
    "  \"val_data\": True,\n",
    "  \"eval_interval\": 1000,\n",
    "  \"save_interval\": 1000,\n",
    "  \"log_interval\": 10,\n",
    "  \"anneal_lr\": True,\n",
    "  \"microbatch\": -1,\n",
    "  \"use_kl\":False,\n",
    "  \"schedule_sampler\": \"uniform\",\n",
    "  \"resume_checkpoint\": False,\n",
    "  \"predict_xstart\":False,\n",
    "  \"rescale_timesteps\":False,\n",
    "  \"rescale_learned_sigmas\":False,\n",
    "  \"timestep_respacing\": \"\",\n",
    "  \"noise_schedule\": \"cosine\",\n",
    "  \"channel_mults\": \"\",\n",
    "  \"loss-type\": \"l2\",\n",
    "  \"loss_weight\": \"none\",\n",
    "  \"train_start\": True,\n",
    "  \"lr\": 1e-4,\n",
    "  \"learn_sigma \": True,\n",
    "  \"random_slice\": True,\n",
    "  \"sample_distance\": 800,\n",
    "  \"weight_decay\": 0.0,\n",
    "  \"save_imgs\": True,\n",
    "  \"save_vids\": True,\n",
    "  \"class_cond \": True,\n",
    "  \"use_fp16\": True,\n",
    "  \"use_scale_shift_norm\": True,\n",
    "  \"dropout\": 0.1,\n",
    "  \"attention_resolutions\": \"32,16,8\",\n",
    "  \"num_res_blocks\": 3,\n",
    "  \"resblock_updown\": True,\n",
    "  \"classifier_use_fp16\":False,\n",
    "  \"classifier_width\":128,\n",
    "  \"classifier_depth\": 2,\n",
    "  \"classifier_attention_resolutions\": \"32,16,8\",\n",
    "  \"classifier_use_scale_shift_norm\": True,\n",
    "  \"classifier_resblock_updown\": True,\n",
    "  \"classifier_pool\": \"attention\" ,\n",
    "  \"num_head_channels\": 64,\n",
    "  \"noised\": True,\n",
    "  \"noise_fn\": \"gauss\",\n",
    "  \"dataset\": \"brats\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0e6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(**args_dict)\n",
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f030bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR= './'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69463b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38b3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b559a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, testing_dataset = dataset.init_datasets(ROOT_DIR, args_dict)\n",
    "datal = dataset.init_dataset_loader(training_dataset, args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e403261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd8104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a457498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e4b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "#     logger.configure()\n",
    "\n",
    "#     logger.log(\"creating model and diffusion...\")\n",
    "    model, diffusion = create_classifier_and_diffusion(args\n",
    "    )\n",
    "    model.to(device)\n",
    "    if args.noised:\n",
    "        schedule_sampler = create_named_schedule_sampler(\n",
    "            args.schedule_sampler, diffusion, maxt=1000\n",
    "        )\n",
    "\n",
    "    resume_step = 0\n",
    "    if args.resume_checkpoint:\n",
    "        resume_step = parse_resume_step_from_filename(args.resume_checkpoint)\n",
    "#         if dist.get_rank() == 0:\n",
    "#         logger.log(\n",
    "#             f\"loading model from checkpoint: {args.resume_checkpoint}... at {resume_step} step\"\n",
    "#         )\n",
    "        model.load_state_dict(\n",
    "            dist_util.load_state_dict(\n",
    "                args.resume_checkpoint, map_location=device\n",
    "            )\n",
    "        )\n",
    "    # Needed for creating correct EMAs and fp16 parameters.\n",
    "#     dist_util.sync_params(model.parameters())\n",
    "\n",
    "    mp_trainer = MixedPrecisionTrainer(\n",
    "        model=model, use_fp16=args.classifier_use_fp16, initial_lg_loss_scale=16.0\n",
    "    )\n",
    "\n",
    "\n",
    "#     logger.log(\"creating data loader...\")\n",
    "    training_dataset, testing_dataset = dataset.init_datasets(ROOT_DIR, args_dict)\n",
    "    datal = dataset.init_dataset_loader(training_dataset, args_dict)\n",
    "    if args.val_data:\n",
    "        val_data = dataset.init_dataset_loader(testing_dataset, args_dict)\n",
    "    else:\n",
    "        val_data = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    logger.log(f\"creating optimizer...\")\n",
    "    opt = AdamW(mp_trainer.master_params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    if args.resume_checkpoint:\n",
    "        opt_checkpoint = bf.join(\n",
    "            bf.dirname(args.resume_checkpoint), f\"opt{resume_step:06}.pt\"\n",
    "        )\n",
    "        logger.log(f\"loading optimizer state from checkpoint: {opt_checkpoint}\")\n",
    "        opt.load_state_dict(\n",
    "            dist_util.load_state_dict(opt_checkpoint, map_location=device)\n",
    "        )\n",
    "\n",
    "    logger.log(\"training classifier model...\")\n",
    "\n",
    "\n",
    "    def forward_backward_log(data_loader, step, prefix=\"train\"):\n",
    "        extra = next(data_loader)\n",
    "        batch = extra[\"image\"].to(device)\n",
    "        labels = extra[\"label\"].to(device)\n",
    "\n",
    "        if args.noised:\n",
    "            t, _ = schedule_sampler.sample(batch.shape[0], dist_util.dev())\n",
    "            batch = diffusion.q_sample(batch, t)\n",
    "        else:\n",
    "            t = th.zeros(batch.shape[0], dtype=th.long, device=dist_util.dev())\n",
    "\n",
    "        for i, (sub_batch, sub_labels, sub_t) in enumerate(\n",
    "            split_microbatches(args.microbatch, batch, labels, t)\n",
    "        ):\n",
    "          \n",
    "            sub_batch = Variable(sub_batch, requires_grad=True)\n",
    "            logits = model(sub_batch, timesteps=sub_t)\n",
    "         \n",
    "            loss = F.cross_entropy(logits, sub_labels, reduction=\"none\")\n",
    "            losses = {}\n",
    "            losses[f\"{prefix}_loss\"] = loss.detach()\n",
    "            losses[f\"{prefix}_acc@1\"] = compute_top_k(\n",
    "                logits, sub_labels, k=1, reduction=\"none\"\n",
    "            )\n",
    "            losses[f\"{prefix}_acc@2\"] = compute_top_k(\n",
    "                logits, sub_labels, k=2, reduction=\"none\"\n",
    "            )\n",
    "#             print('acc', losses[f\"{prefix}_acc@1\"])\n",
    "            log_loss_dict(diffusion, sub_t, losses)\n",
    "\n",
    "            loss = loss.mean()\n",
    "            if prefix==\"train\":\n",
    "                viz.line(X=th.ones((1, 1)).cpu() * step, Y=th.Tensor([loss]).unsqueeze(0).cpu(),\n",
    "                     win=loss_window, name='loss_cls',\n",
    "                     update='append')\n",
    "\n",
    "            else:\n",
    "                output_idx = logits[0].argmax()\n",
    "#                 print('outputidx', output_idx)\n",
    "                output_max = logits[0, output_idx]\n",
    "#                 print('outmax', output_max, output_max.shape)\n",
    "                output_max.backward()\n",
    "                saliency, _ = th.max(sub_batch.grad.data.abs(), dim=1)\n",
    "#                 print('saliency', saliency.shape)\n",
    "                viz.heatmap(visualize(saliency[0, ...]))\n",
    "                viz.image(visualize(sub_batch[0, 0,...]))\n",
    "                viz.image(visualize(sub_batch[0, 1, ...]))\n",
    "                th.cuda.empty_cache()\n",
    "\n",
    "\n",
    "            if loss.requires_grad and prefix==\"train\":\n",
    "                if i == 0:\n",
    "                    mp_trainer.zero_grad()\n",
    "                mp_trainer.backward(loss * len(sub_batch) / len(batch))\n",
    "\n",
    "        return losses\n",
    "\n",
    "    correct=0; total=0\n",
    "    for step in tqdm(range(args.iterations - resume_step)):\n",
    "        logger.logkv(\"step\", step + resume_step)\n",
    "        logger.logkv(\n",
    "            \"samples\",\n",
    "            (step + resume_step + 1) * args.batch_size,\n",
    "        )\n",
    "        if args.anneal_lr:\n",
    "            set_annealed_lr(opt, args.lr, (step + resume_step) / args.iterations)\n",
    "#         print('step', step + resume_step)\n",
    "        try:\n",
    "            losses = forward_backward_log(data, step + resume_step)\n",
    "        except:\n",
    "            data = iter(datal)\n",
    "            losses = forward_backward_log(data, step + resume_step)\n",
    "\n",
    "        correct+=losses[\"train_acc@1\"].sum()\n",
    "        total+=args.batch_size\n",
    "        acctrain=correct/total\n",
    "\n",
    "        mp_trainer.optimize(opt)\n",
    "          \n",
    "        if val_data is not None and not step % args.eval_interval:\n",
    "            model.eval()\n",
    "            forward_backward_log(val_data, step, prefix=\"val\")\n",
    "            model.train()\n",
    "        if not step % args.log_interval:\n",
    "            logger.dumpkvs()\n",
    "        if (step + resume_step) % args.save_interval:\n",
    "            logger.log(\"saving model...\")\n",
    "            save_model(mp_trainer, opt, step + resume_step)\n",
    "\n",
    "#     if dist.get_rank() == 0:\n",
    "    logger.log(\"saving model...\")\n",
    "    save_model(mp_trainer, opt, step + resume_step)\n",
    "#     dist.barrier()\n",
    "\n",
    "\n",
    "def set_annealed_lr(opt, base_lr, frac_done):\n",
    "    lr = base_lr * (1 - frac_done)\n",
    "    for param_group in opt.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "def save_model(mp_trainer, opt, step):\n",
    "    th.save(\n",
    "        mp_trainer.master_params_to_state_dict(mp_trainer.master_params),\n",
    "        os.path.join(logger.get_dir(), f\"model{step:06d}.pt\"),\n",
    "    )\n",
    "    th.save(opt.state_dict(), os.path.join(logger.get_dir(), f\"opt{step:06d}.pt\"))\n",
    "\n",
    "\n",
    "def compute_top_k(logits, labels, k, reduction=\"mean\"):\n",
    "    _, top_ks = th.topk(logits, k, dim=-1)\n",
    "    if reduction == \"mean\":\n",
    "        return (top_ks == labels[:, None]).float().sum(dim=-1).mean().item()\n",
    "    elif reduction == \"none\":\n",
    "        return (top_ks == labels[:, None]).float().sum(dim=-1)\n",
    "\n",
    "\n",
    "def split_microbatches(microbatch, *args):\n",
    "    bs = len(args[0])\n",
    "    if microbatch == -1 or microbatch >= bs:\n",
    "        yield tuple(args)\n",
    "    else:\n",
    "        for i in range(0, bs, microbatch):\n",
    "            yield tuple(x[i : i + microbatch] if x is not None else None for x in args)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3c3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff60a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
