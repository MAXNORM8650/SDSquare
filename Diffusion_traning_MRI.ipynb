{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc04eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "from random import seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from torch import optim\n",
    "\n",
    "import dataset\n",
    "import evaluation\n",
    "from GaussianDiffusion import GaussianDiffusionModel, get_beta_schedule\n",
    "from helpers import *\n",
    "from UNet import UNetModel, update_ema_params\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "ROOT_DIR = \"./\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e186e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "  \"img_size\": [\n",
    "    256,\n",
    "    256\n",
    "  ],\n",
    "  \"Batch_Size\": 1,\n",
    "  \"EPOCHS\": 4000,\n",
    "  \"T\": 1000,\n",
    "  \"base_channels\": 128,\n",
    "  \"channels\": 1,\n",
    "  \"beta_schedule\": \"cosine\",\n",
    "  \"channel_mults\": \"\",\n",
    "  \"loss-type\": \"l2\",\n",
    "  \"loss_weight\": \"none\",\n",
    "  \"train_start\": True,\n",
    "  \"lr\": 1e-4,\n",
    "  \"random_slice\": False,\n",
    "  \"sample_distance\": 800,\n",
    "  \"weight_decay\": 0.0,\n",
    "  \"save_imgs\": True,\n",
    "  \"save_vids\": True,\n",
    "  \"dropout\": 0,\n",
    "  \"attention_resolutions\": \"16,8\",\n",
    "  \"num_heads\": 2,\n",
    "  \"num_head_channels\": -1,\n",
    "  \"noise_fn\": \"simplex\",\n",
    "  \"dataset\": \"mri\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4263d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a42a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db65463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = r\"C:\\Users\\Admin\\Dropbox\\PC\\Documents\\Anomaly Detection\\AnoDDPM\\data\\brats\\training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "029c7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./DATASETS/CancerousDataset\"\n",
    "patients = os.listdir(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad3ca6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalous-T1\n",
      "00000\n",
      "00002\n",
      "00003\n",
      "00005\n",
      "00006\n",
      "00008\n",
      "00009\n",
      "00011\n",
      "00012\n",
      "00014\n",
      "00016\n",
      "00017\n",
      "00018\n",
      "00019\n",
      "00020\n",
      "00021\n",
      "00022\n",
      "00024\n",
      "00025\n",
      "00026\n"
     ]
    }
   ],
   "source": [
    "for i in patients:\n",
    "    print(i.split(\"_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc7a8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(save_videos=True, bias_corrected=False, verbose=0):\n",
    "    DATASET = \"./DATASETS/CancerousDataset\"\n",
    "#     try:\n",
    "#         os.makedirs(os.path.join(DATASET,\"T1w\"))\n",
    "#     except OSError:\n",
    "#         pass\n",
    "#     DATASET = os.path.join(DATASET,\"T1w\")\n",
    "    patients = os.listdir(DATASET)\n",
    "#     print(patients)\n",
    "    for patient in patients:\n",
    "        try:\n",
    "            i_d = patient.split(\"_\")[-1]\n",
    "            print(i_d)\n",
    "            patient_data = os.listdir(f\"{DATASET}/{i_d}\")\n",
    "        except:\n",
    "            if verbose:\n",
    "                print(f\"{DATASET}/{patient} Not a directory\")\n",
    "            continue\n",
    "        for data_folder in patient_data:\n",
    "            if \"COR_3D\" in data_folder:\n",
    "                try:\n",
    "                    T1_files = os.listdir(f\"{DATASET}/{patient}/{data_folder}\")\n",
    "                except:\n",
    "                    if verbose:\n",
    "                        print(f\"{patient}/{data_folder} not a directory\")\n",
    "                    continue\n",
    "                try:\n",
    "                    mask_dir = os.listdir(f\"{DATASET}/{patient}/tissue_classes\")\n",
    "                    for file in mask_dir:\n",
    "                        if file.startswith(\"cleaned\") and file.endswith(\".nii\"):\n",
    "                            mask_file = file\n",
    "                except:\n",
    "                    if verbose:\n",
    "                        print(f\"{DATASET}/{patient}/tissue_classes dir not found\")\n",
    "                    return\n",
    "                for t1 in T1_files:\n",
    "                    if bias_corrected:\n",
    "                        check = t1.endswith(\"corrected.nii\")\n",
    "                    else:\n",
    "                        check = t1.startswith(\"anon\")\n",
    "                    if check and t1.endswith(\".nii\"):\n",
    "                        # try:\n",
    "                        # use slice 35-55\n",
    "                        img = nib.load(f\"{DATASET}/{patient}/{data_folder}/{t1}\")\n",
    "                        mask = nib.load(f\"{DATASET}/{patient}/tissue_classes/{mask_file}\").get_fdata()\n",
    "                        image = img.get_fdata()\n",
    "                        if verbose:\n",
    "                            print(image.shape)\n",
    "                        if bias_corrected:\n",
    "                            # image.shape = (256, 156, 256)\n",
    "                            image = np.rot90(image, 3, (0, 2))\n",
    "                            image = np.flip(image, 1)\n",
    "                            # image.shape = (256, 156, 256)\n",
    "                        else:\n",
    "                            image = np.transpose(image, (1, 2, 0))\n",
    "                        mask = np.transpose(mask, (1, 2, 0))\n",
    "                        if verbose:\n",
    "                            print(image.shape)\n",
    "                        image_mean = np.mean(image)\n",
    "                        image_std = np.std(image)\n",
    "                        img_range = (image_mean - 1 * image_std, image_mean + 2 * image_std)\n",
    "                        image = np.clip(image, img_range[0], img_range[1])\n",
    "                        image = image / (img_range[1] - img_range[0])\n",
    "\n",
    "                        np.save(\n",
    "                                f\"{DATASET}/Anomalous-T1/raw_new/{patient}.npy\", image.astype(\n",
    "                                        np.float32\n",
    "                                        )\n",
    "                                )\n",
    "                        np.save(\n",
    "                                f\"{DATASET}/Anomalous-T1/mask_new/{patient}.npy\", mask.astype(\n",
    "                                        np.float32\n",
    "                                        )\n",
    "                                )\n",
    "                        if verbose:\n",
    "                            print(f\"Saved {DATASET}/Anomalous-T1/mask/{patient}.npy\")\n",
    "\n",
    "                        if save_videos:\n",
    "                            fig = plt.figure()\n",
    "                            ims = []\n",
    "                            for i in range(image.shape[0]):\n",
    "                                tempImg = image[i:i + 1, :, :]\n",
    "                                im = plt.imshow(\n",
    "                                        tempImg.reshape(image.shape[1], image.shape[2]), cmap='gray', animated=True\n",
    "                                        )\n",
    "                                ims.append([im])\n",
    "\n",
    "                            ani = animation.ArtistAnimation(\n",
    "                                    fig, ims, interval=50, blit=True,\n",
    "                                    repeat_delay=1000\n",
    "                                    )\n",
    "\n",
    "                            ani.save(f\"{DATASET}/Anomalous-T1/raw_new/videos/{patient}.gif\")\n",
    "                            if verbose:\n",
    "                                print(f\"Saved {DATASET}/Anomalous-T1/raw/videos/{patient}.gif\")\n",
    "                            fig = plt.figure()\n",
    "                            ims = []\n",
    "                            for i in range(mask.shape[0]):\n",
    "                                tempImg = mask[i:i + 1, :, :]\n",
    "                                im = plt.imshow(\n",
    "                                        tempImg.reshape(mask.shape[1], mask.shape[2]), cmap='gray', animated=True\n",
    "                                        )\n",
    "                                ims.append([im])\n",
    "\n",
    "                            ani = animation.ArtistAnimation(\n",
    "                                    fig, ims, interval=50, blit=True,\n",
    "                                    repeat_delay=1000\n",
    "                                    )\n",
    "\n",
    "                            ani.save(f\"{DATASET}/Anomalous-T1/mask_new/videos/{patient}.gif\")\n",
    "                            if verbose:\n",
    "                                print(mask.shape)\n",
    "                                print(f\"Saved {DATASET}/Anomalous-T1/raw/videos/{patient}.gif\")\n",
    "    for i in [f\"{DATASET}/Anomalous-T1/raw_new\", f\"{DATASET}/Anomalous-T1/mask_new\"]:\n",
    "        try:\n",
    "            os.makedirs(i)\n",
    "        except OSError:\n",
    "            pass\n",
    "    if save_videos:\n",
    "        for i in [f\"{DATASET}/Anomalous-T1/raw_new/videos\", f\"{DATASET}/Anomalous-T1/mask_new/videos\"]:\n",
    "            try:\n",
    "                os.makedirs(i)\n",
    "            except OSError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "882d4200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalous-T1\n",
      "00000\n",
      "00002\n",
      "00003\n",
      "00005\n",
      "00006\n",
      "00008\n",
      "00009\n",
      "00011\n",
      "00012\n",
      "00014\n",
      "00016\n",
      "00017\n",
      "00018\n",
      "00019\n",
      "00020\n",
      "00021\n",
      "00022\n",
      "00024\n",
      "00025\n",
      "00026\n",
      "T1w\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8663eae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"load_datasets\"\n",
    "x.split(\"_\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82481ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnnMRI = dataset.load_datasets_for_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffd0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in AnnMRI:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425299bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7cfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb777e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84216a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetModel(\n",
    "            args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], dropout=args[\n",
    "                \"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "            in_channels=args[\"channels\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cef12ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 256, 256)\n",
    "t_batch = torch.tensor([1], device=x.device).repeat(x.shape[0])\n",
    "print(model(x, t_batch)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32f3fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73958c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = get_beta_schedule(args['T'], args['beta_schedule'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490a21fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low is out of bounds for int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m \u001b[43mGaussianDiffusionModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss-type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnoise_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:171\u001b[0m, in \u001b[0;36mGaussianDiffusionModel.__init__\u001b[1;34m(self, img_size, betas, img_channels, loss_type, loss_weight, noise)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, t: torch\u001b[38;5;241m.\u001b[39mrandn_like(x)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimplex \u001b[38;5;241m=\u001b[39m \u001b[43mSimplex_CLASS\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m noise \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplex_randParam\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x, t: generate_simplex_noise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimplex, x, t, \u001b[38;5;28;01mTrue\u001b[39;00m, in_channels\u001b[38;5;241m=\u001b[39mimg_channels)\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\simplex.py:17\u001b[0m, in \u001b[0;36mSimplex_CLASS.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewSeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\simplex.py:21\u001b[0m, in \u001b[0;36mSimplex_CLASS.newSeed\u001b[1;34m(self, seed)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnewSeed\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seed:\n\u001b[1;32m---> 21\u001b[0m         seed \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10000000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000000000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perm_grad_index3 \u001b[38;5;241m=\u001b[39m _init(seed)\n",
      "File \u001b[1;32mmtrand.pyx:746\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_bounded_integers.pyx:1334\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low is out of bounds for int32"
     ]
    }
   ],
   "source": [
    "diffusion = GaussianDiffusionModel(\n",
    "        args['img_size'], betas, loss_weight=args['loss_weight'],\n",
    "        loss_type=args['loss-type'], noise=args[\"noise_fn\"], img_channels=args[\"channels\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820fa05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oss, estimates = diffusion.p_loss(model, x, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493981d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc457fc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, 256, 256].  Tensor sizes: [4, 256, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 322\u001b[0m\n\u001b[0;32m    319\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 322\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 310\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    307\u001b[0m         loaded_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(file_dir, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# load, pass args\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_dataset_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# remove checkpoints after final_param is saved (due to storage requirements)\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_remove \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model/diff-params-ARGS=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_num\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[19], line 78\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     75\u001b[0m     x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     76\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 78\u001b[0m loss, estimates \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m noisy, est \u001b[38;5;241m=\u001b[39m estimates[\u001b[38;5;241m1\u001b[39m], estimates[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     81\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:429\u001b[0m, in \u001b[0;36mp_loss\u001b[1;34m(self, model, x_0, args)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_start\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    428\u001b[0m         t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\n\u001b[1;32m--> 429\u001b[0m                 \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps), (x_0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],),\n\u001b[0;32m    430\u001b[0m                 device\u001b[38;5;241m=\u001b[39mx_0\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    431\u001b[0m                 )\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m         t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps, (x_0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), device\u001b[38;5;241m=\u001b[39mx_0\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:399\u001b[0m, in \u001b[0;36mcalc_loss\u001b[1;34m(self, model, x_0, t)\u001b[0m\n\u001b[0;32m    394\u001b[0m kl \u001b[38;5;241m=\u001b[39m normal_kl(true_mean, true_log_var, output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m], output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    395\u001b[0m kl \u001b[38;5;241m=\u001b[39m mean_flat(kl) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2.0\u001b[39m)\n\u001b[0;32m    397\u001b[0m decoder_nll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mdiscretised_gaussian_log_likelihood(\n\u001b[0;32m    398\u001b[0m         x_0, output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m], log_scales\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 399\u001b[0m         )\n\u001b[0;32m    400\u001b[0m decoder_nll \u001b[38;5;241m=\u001b[39m mean_flat(decoder_nll) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2.0\u001b[39m)\n\u001b[0;32m    402\u001b[0m nll \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere((t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), decoder_nll, kl)\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:170\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x, t)\u001b[0m\n\u001b[0;32m    167\u001b[0m if noise == \"gauss\":\n\u001b[0;32m    168\u001b[0m     self.noise_fn = lambda x, t: torch.randn_like(x)\n\u001b[1;32m--> 170\u001b[0m else:\n\u001b[0;32m    171\u001b[0m     self.simplex = Simplex_CLASS()\n\u001b[0;32m    172\u001b[0m     if noise == \"simplex_randParam\":\n",
      "File \u001b[1;32m~\\Documents\\Anomaly Detection\\AnoDDPM\\GaussianDiffusion.py:124\u001b[0m, in \u001b[0;36mgenerate_simplex_noise\u001b[1;34m(Simplex_instance, x, t, random_param, octave, persistence, frequency, in_channels)\u001b[0m\n\u001b[0;32m    107\u001b[0m             param \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\n\u001b[0;32m    108\u001b[0m                     [(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m16\u001b[39m), (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m32\u001b[39m), (\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m32\u001b[39m), (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m64\u001b[39m), (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m16\u001b[39m), (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m16\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m    109\u001b[0m                      (\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m128\u001b[39m), (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m64\u001b[39m), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.85\u001b[39m, \u001b[38;5;241m128\u001b[39m), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.85\u001b[39m, \u001b[38;5;241m64\u001b[39m), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.85\u001b[39m, \u001b[38;5;241m32\u001b[39m), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.85\u001b[39m, \u001b[38;5;241m16\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m                      (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.85\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.85\u001b[39m, \u001b[38;5;241m2\u001b[39m), ]\n\u001b[0;32m    114\u001b[0m                     )\n\u001b[0;32m    115\u001b[0m             \u001b[38;5;66;03m# 2D octaves seem to introduce directional artifacts in the top left\u001b[39;00m\n\u001b[0;32m    116\u001b[0m             \u001b[43mnoise\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(\n\u001b[0;32m    117\u001b[0m                     torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\n\u001b[0;32m    118\u001b[0m                             \u001b[38;5;66;03m# Simplex_instance.rand_2d_octaves(\u001b[39;00m\n\u001b[0;32m    119\u001b[0m                             \u001b[38;5;66;03m#         x.shape[-2:], param[0], param[1],\u001b[39;00m\n\u001b[0;32m    120\u001b[0m                             \u001b[38;5;66;03m#         param[2]\u001b[39;00m\n\u001b[0;32m    121\u001b[0m                             \u001b[38;5;66;03m#         )\u001b[39;00m\n\u001b[0;32m    122\u001b[0m                             Simplex_instance\u001b[38;5;241m.\u001b[39mrand_3d_fixed_T_octaves(\n\u001b[0;32m    123\u001b[0m                                     x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:], t\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), param[\u001b[38;5;241m0\u001b[39m], param[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m--> 124\u001b[0m                                     param[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    125\u001b[0m                                     )\n\u001b[0;32m    126\u001b[0m                             )\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice), \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    127\u001b[0m                     )\u001b[38;5;241m.\u001b[39mrepeat(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi and in_channels \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m#         print(\"noise shape\", noise.shape)\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#         print(\"t shape\", t.shape)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [1, 256, 256].  Tensor sizes: [4, 256, 256]"
     ]
    }
   ],
   "source": [
    "def train(training_dataset_loader, testing_dataset_loader, args, resume):\n",
    "    \"\"\"\n",
    "\n",
    "    :param training_dataset_loader: cycle(dataloader) instance for training\n",
    "    :param testing_dataset_loader:  cycle(dataloader) instance for testing\n",
    "    :param args: dictionary of parameters\n",
    "    :param resume: dictionary of parameters if continuing training from checkpoint\n",
    "    :return: Trained model and tested\n",
    "    \"\"\"\n",
    "\n",
    "    in_channels = 1\n",
    "    if args[\"dataset\"].lower() == \"cifar\" or args[\"dataset\"].lower() == \"leather\":\n",
    "        in_channels = 3\n",
    "    if args[\"dataset\"].lower() == \"brats\":\n",
    "        in_channels = 4\n",
    "    if args[\"channels\"] != \"\":\n",
    "        in_channels = args[\"channels\"]\n",
    "\n",
    "    model = UNetModel(\n",
    "            args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], dropout=args[\n",
    "                \"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "            in_channels=args[\"channels\"]\n",
    "            )\n",
    "\n",
    "    betas = get_beta_schedule(args['T'], args['beta_schedule'])\n",
    "\n",
    "    diffusion = GaussianDiffusionModel(\n",
    "            args['img_size'], betas, loss_weight=args['loss_weight'],\n",
    "            loss_type=args['loss-type'], noise=args[\"noise_fn\"], img_channels=args[\"channels\"]\n",
    "            )\n",
    "\n",
    "    if resume:\n",
    "\n",
    "        if \"unet\" in resume:\n",
    "            model.load_state_dict(resume[\"unet\"])\n",
    "        else:\n",
    "            model.load_state_dict(resume[\"ema\"])\n",
    "\n",
    "        ema = UNetModel(\n",
    "                args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'],\n",
    "                dropout=args[\"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "                in_channels=in_channels\n",
    "                )\n",
    "        ema.load_state_dict(resume[\"ema\"])\n",
    "        start_epoch = resume['n_epoch']\n",
    "\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        ema = copy.deepcopy(model)\n",
    "\n",
    "    tqdm_epoch = range(start_epoch, args['EPOCHS'] + 1)\n",
    "    model.to(device)\n",
    "    ema.to(device)\n",
    "    optimiser = optim.AdamW(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'], betas=(0.9, 0.999))\n",
    "    if resume:\n",
    "        optimiser.load_state_dict(resume[\"optimizer_state_dict\"])\n",
    "\n",
    "    del resume\n",
    "    start_time = time.time()\n",
    "    losses = []\n",
    "    vlb = collections.deque([], maxlen=10)\n",
    "    iters = range(100 // args['Batch_Size']) if args[\"dataset\"].lower() != \"cifar\" else range(200)\n",
    "    # iters = range(100 // args['Batch_Size']) if args[\"dataset\"].lower() != \"cifar\" else range(150)\n",
    "\n",
    "    # dataset loop\n",
    "    for epoch in tqdm_epoch:\n",
    "        mean_loss = []\n",
    "\n",
    "        for i in iters:\n",
    "            data = next(training_dataset_loader)\n",
    "            if args[\"dataset\"] == \"cifar\":\n",
    "                # cifar outputs [data,class]\n",
    "                x = data[0].to(device)\n",
    "            else:\n",
    "                x = data[\"image\"]\n",
    "                x = x.to(device)\n",
    "\n",
    "            loss, estimates = diffusion.p_loss(model, x, args)\n",
    "\n",
    "            noisy, est = estimates[1], estimates[2]\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimiser.step()\n",
    "\n",
    "            update_ema_params(ema, model)\n",
    "            mean_loss.append(loss.data.cpu())\n",
    "\n",
    "            if epoch % 50 == 0 and i == 0:\n",
    "                row_size = min(8, args['Batch_Size'])\n",
    "                training_outputs(\n",
    "                        diffusion, x, est, noisy, epoch, row_size, save_imgs=args['save_imgs'],\n",
    "                        save_vids=args['save_vids'], ema=ema, args=args\n",
    "                        )\n",
    "\n",
    "        losses.append(np.mean(mean_loss))\n",
    "        if epoch % 200 == 0:\n",
    "            time_taken = time.time() - start_time\n",
    "            remaining_epochs = args['EPOCHS'] - epoch\n",
    "            time_per_epoch = time_taken / (epoch + 1 - start_epoch)\n",
    "            hours = remaining_epochs * time_per_epoch / 3600\n",
    "            mins = (hours % 1) * 60\n",
    "            hours = int(hours)\n",
    "\n",
    "            vlb_terms = diffusion.calc_total_vlb(x, model, args)\n",
    "            vlb.append(vlb_terms[\"total_vlb\"].mean(dim=-1).cpu().item())\n",
    "            print(\n",
    "                    f\"epoch: {epoch}, most recent total VLB: {vlb[-1]} mean total VLB:\"\n",
    "                    f\" {np.mean(vlb):.4f}, \"\n",
    "                    f\"prior vlb: {vlb_terms['prior_vlb'].mean(dim=-1).cpu().item():.2f}, vb: \"\n",
    "                    f\"{torch.mean(vlb_terms['vb'], dim=list(range(2))).cpu().item():.2f}, x_0_mse: \"\n",
    "                    f\"{torch.mean(vlb_terms['x_0_mse'], dim=list(range(2))).cpu().item():.2f}, mse: \"\n",
    "                    f\"{torch.mean(vlb_terms['mse'], dim=list(range(2))).cpu().item():.2f}\"\n",
    "                    f\" time elapsed {int(time_taken / 3600)}:{((time_taken / 3600) % 1) * 60:02.0f}, \"\n",
    "                    f\"est time remaining: {hours}:{mins:02.0f}\\r\"\n",
    "                    )\n",
    "            # else:\n",
    "            #\n",
    "            #     print(\n",
    "            #             f\"epoch: {epoch}, imgs trained: {(i + 1) * args['Batch_Size'] + epoch * 100}, last 20 epoch mean loss:\"\n",
    "            #             f\" {np.mean(losses[-20:]):.4f} , last 100 epoch mean loss:\"\n",
    "            #             f\" {np.mean(losses[-100:]) if len(losses) > 0 else 0:.4f}, \"\n",
    "            #             f\"time per epoch {time_per_epoch:.2f}s, time elapsed {int(time_taken / 3600)}:\"\n",
    "            #             f\"{((time_taken / 3600) % 1) * 60:02.0f}, est time remaining: {hours}:{mins:02.0f}\\r\"\n",
    "            #             )\n",
    "\n",
    "        if epoch % 1000 == 0 and epoch >= 0:\n",
    "            save(unet=model, args=args, optimiser=optimiser, final=False, ema=ema, epoch=epoch)\n",
    "\n",
    "    save(unet=model, args=args, optimiser=optimiser, final=True, ema=ema)\n",
    "\n",
    "    evaluation.testing(testing_dataset_loader, diffusion, ema=ema, args=args, model=model)\n",
    "\n",
    "\n",
    "def save(final, unet, optimiser, args, ema, loss=0, epoch=0):\n",
    "    \"\"\"\n",
    "    Save model final or checkpoint\n",
    "    :param final: bool for final vs checkpoint\n",
    "    :param unet: unet instance\n",
    "    :param optimiser: ADAM optim\n",
    "    :param args: model parameters\n",
    "    :param ema: ema instance\n",
    "    :param loss: loss for checkpoint\n",
    "    :param epoch: epoch for checkpoint\n",
    "    :return: saved model\n",
    "    \"\"\"\n",
    "    if final:\n",
    "        torch.save(\n",
    "                {\n",
    "                    'n_epoch':              args[\"EPOCHS\"],\n",
    "                    'model_state_dict':     unet.state_dict(),\n",
    "                    'optimizer_state_dict': optimiser.state_dict(),\n",
    "                    \"ema\":                  ema.state_dict(),\n",
    "                    \"args\":                 args\n",
    "                    # 'loss': LOSS,\n",
    "                    }, f'{ROOT_DIR}model/diff-params-ARGS={args[\"arg_num\"]}/params-final.pt'\n",
    "                )\n",
    "    else:\n",
    "        torch.save(\n",
    "                {\n",
    "                    'n_epoch':              epoch,\n",
    "                    'model_state_dict':     unet.state_dict(),\n",
    "                    'optimizer_state_dict': optimiser.state_dict(),\n",
    "                    \"args\":                 args,\n",
    "                    \"ema\":                  ema.state_dict(),\n",
    "                    'loss':                 loss,\n",
    "                    }, f'{ROOT_DIR}model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint/diff_epoch={epoch}.pt'\n",
    "                )\n",
    "\n",
    "\n",
    "def training_outputs(diffusion, x, est, noisy, epoch, row_size, ema, args, save_imgs=False, save_vids=False):\n",
    "    \"\"\"\n",
    "    Saves video & images based on args info\n",
    "    :param diffusion: diffusion model instance\n",
    "    :param x: x_0 real data value\n",
    "    :param est: estimate of the noise at x_t (output of the model)\n",
    "    :param noisy: x_t\n",
    "    :param epoch:\n",
    "    :param row_size: rows for outputs into torchvision.utils.make_grid\n",
    "    :param ema: exponential moving average unet for sampling\n",
    "    :param save_imgs: bool for saving imgs\n",
    "    :param save_vids: bool for saving diffusion videos\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(f'./diffusion-videos/ARGS={args[\"arg_num\"]}')\n",
    "        os.makedirs(f'./diffusion-training-images/ARGS={args[\"arg_num\"]}')\n",
    "    except OSError:\n",
    "        pass\n",
    "    if save_imgs:\n",
    "        if epoch % 100 == 0:\n",
    "            # for a given t, output x_0, & prediction of x_(t-1), and x_0\n",
    "            noise = torch.rand_like(x)\n",
    "            t = torch.randint(0, diffusion.num_timesteps, (x.shape[0],), device=x.device)\n",
    "            x_t = diffusion.sample_q(x, t, noise)\n",
    "            temp = diffusion.sample_p(ema, x_t, t)\n",
    "            out = torch.cat(\n",
    "                    (x[:row_size, ...].cpu(), temp[\"sample\"][:row_size, ...].cpu(),\n",
    "                     temp[\"pred_x_0\"][:row_size, ...].cpu())\n",
    "                    )\n",
    "            plt.title(f'real,sample,prediction x_0-{epoch}epoch')\n",
    "        else:\n",
    "            # for a given t, output x_0, x_t, & prediction of noise in x_t & MSE\n",
    "            out = torch.cat(\n",
    "                    (x[:row_size, ...].cpu(), noisy[:row_size, ...].cpu(), est[:row_size, ...].cpu(),\n",
    "                     (est - noisy).square().cpu()[:row_size, ...])\n",
    "                    )\n",
    "            plt.title(f'real,noisy,noise prediction,mse-{epoch}epoch')\n",
    "        plt.rcParams['figure.dpi'] = 150\n",
    "        plt.grid(False)\n",
    "        plt.imshow(gridify_output(out, row_size), cmap='gray')\n",
    "\n",
    "        plt.savefig(f'./diffusion-training-images/ARGS={args[\"arg_num\"]}/EPOCH={epoch}.png')\n",
    "        plt.clf()\n",
    "    if save_vids:\n",
    "        fig, ax = plt.subplots()\n",
    "        if epoch % 500 == 0:\n",
    "            plt.rcParams['figure.dpi'] = 200\n",
    "            if epoch % 1000 == 0:\n",
    "                out = diffusion.forward_backward(ema, x, \"half\", args['sample_distance'] // 2, denoise_fn=\"noise_fn\")\n",
    "            else:\n",
    "                out = diffusion.forward_backward(ema, x, \"half\", args['sample_distance'] // 4, denoise_fn=\"noise_fn\")\n",
    "            imgs = [[ax.imshow(gridify_output(x, row_size), animated=True)] for x in out]\n",
    "            ani = animation.ArtistAnimation(\n",
    "                    fig, imgs, interval=50, blit=True,\n",
    "                    repeat_delay=1000\n",
    "                    )\n",
    "\n",
    "            ani.save(f'{ROOT_DIR}diffusion-videos/ARGS={args[\"arg_num\"]}/sample-EPOCH={epoch}.gif')            \n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "        Load arguments, run training and testing functions, then remove checkpoint directory\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # make directories\n",
    "    for i in ['./model/', \"./diffusion-videos/\", './diffusion-training-images/']:\n",
    "        try:\n",
    "            os.makedirs(i)\n",
    "        except OSError:\n",
    "            pass\n",
    "    resume = False\n",
    "    # read file from argument\n",
    "    # if dataset is cifar, load different training & test set\n",
    "    if args[\"dataset\"].lower() == \"cifar\":\n",
    "        training_dataset_loader_, testing_dataset_loader_ = dataset.load_CIFAR10(args, True), \\\n",
    "                                                            dataset.load_CIFAR10(args, False)\n",
    "        training_dataset_loader = dataset.cycle(training_dataset_loader_)\n",
    "        testing_dataset_loader = dataset.cycle(testing_dataset_loader_)\n",
    "    elif args[\"dataset\"].lower() == \"carpet\":\n",
    "        training_dataset = dataset.DAGM(\n",
    "                \"./DATASETS/CARPET/Class1\", False, args[\"img_size\"],\n",
    "                False\n",
    "                )\n",
    "        training_dataset_loader = dataset.init_dataset_loader(training_dataset, args)\n",
    "        testing_dataset = dataset.DAGM(\n",
    "                \"./DATASETS/CARPET/Class1\", True, args[\"img_size\"],\n",
    "                False\n",
    "                )\n",
    "        testing_dataset_loader = dataset.init_dataset_loader(testing_dataset, args)\n",
    "    elif args[\"dataset\"].lower() == \"leather\":\n",
    "        if in_channels == 3:\n",
    "            training_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=False, img_size=args[\"img_size\"],\n",
    "                    rgb=True\n",
    "                    )\n",
    "            testing_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=True, img_size=args[\"img_size\"],\n",
    "                    rgb=True, include_good=True\n",
    "                    )\n",
    "        else:\n",
    "            training_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=False, img_size=args[\"img_size\"],\n",
    "                    rgb=False\n",
    "                    )\n",
    "            testing_dataset = dataset.MVTec(\n",
    "                    \"./DATASETS/leather\", anomalous=True, img_size=args[\"img_size\"],\n",
    "                    rgb=False, include_good=True\n",
    "                    )\n",
    "        training_dataset_loader = dataset.init_dataset_loader(training_dataset, args)\n",
    "        testing_dataset_loader = dataset.init_dataset_loader(testing_dataset, args)\n",
    "    else:\n",
    "        # load NFBS dataset\n",
    "        training_dataset, testing_dataset = dataset.init_datasets(ROOT_DIR, args)\n",
    "        training_dataset_loader = dataset.init_dataset_loader(training_dataset, args)\n",
    "        testing_dataset_loader = dataset.init_dataset_loader(testing_dataset, args)\n",
    "\n",
    "    # if resuming, loaded model is attached to the dictionary\n",
    "    loaded_model = {}\n",
    "    if resume:\n",
    "        if resume == 1:\n",
    "            checkpoints = os.listdir(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint')\n",
    "            checkpoints.sort(reverse=True)\n",
    "            for i in checkpoints:\n",
    "                try:\n",
    "                    file_dir = f\"./model/diff-params-ARGS={args['arg_num']}/checkpoint/{i}\"\n",
    "                    loaded_model = torch.load(file_dir, map_location=device)\n",
    "                    break\n",
    "                except RuntimeError:\n",
    "                    continue\n",
    "\n",
    "        else:\n",
    "            file_dir = f'./model/diff-params-ARGS={args[\"arg_num\"]}/params-final.pt'\n",
    "            loaded_model = torch.load(file_dir, map_location=device)\n",
    "\n",
    "    # load, pass args\n",
    "    train(training_dataset_loader, testing_dataset_loader, args, loaded_model)\n",
    "\n",
    "    # remove checkpoints after final_param is saved (due to storage requirements)\n",
    "    for file_remove in os.listdir(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint'):\n",
    "        os.remove(os.path.join(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint', file_remove))\n",
    "    os.removedirs(f'./model/diff-params-ARGS={args[\"arg_num\"]}/checkpoint')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    seed(1)\n",
    "\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982eb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
